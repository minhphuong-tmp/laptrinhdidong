# üìã TODOLIST: Chunk Upload cho ·∫¢nh/Video trong Tin Nh·∫Øn

## üéØ M·ª•c ti√™u
T·ªëi ∆∞u th·ªùi gian upload ·∫£nh v√† video b·∫±ng c√°ch chia file th√†nh nhi·ªÅu chunks nh·ªè v√† upload song song (parallel), gi·∫£m memory overhead v√† tƒÉng t·ªëc ƒë·ªô upload.

---

## üèóÔ∏è PHASE 1: Thi·∫øt k·∫ø & Setup

### ‚úÖ Task 1: Ph√¢n t√≠ch v√† thi·∫øt k·∫ø ki·∫øn tr√∫c
**M√¥ t·∫£:** X√°c ƒë·ªãnh c√°c th√¥ng s·ªë k·ªπ thu·∫≠t v√† flow t·ªïng th·ªÉ

**Chi ti·∫øt:**
- [x] X√°c ƒë·ªãnh chunk size: 2MB (c√¢n b·∫±ng) ho·∫∑c 5MB (nhanh h∆°n nh∆∞ng t·ªën memory h∆°n) ‚Üí **ƒê√£ ch·ªçn: 2MB**
- [x] X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng parallel uploads: 3-5 chunks c√πng l√∫c ‚Üí **ƒê√£ ch·ªçn: 3 chunks**
- [x] Thi·∫øt k·∫ø flow: Client chia chunks ‚Üí Upload parallel ‚Üí Edge Function merge ‚Üí Tr·∫£ v·ªÅ URL ‚Üí **ƒê√£ thi·∫øt k·∫ø**
- [x] Quy·∫øt ƒë·ªãnh c·∫•u tr√∫c th∆∞ m·ª•c temp: `temp/chunks/{fileId}/chunk_{index}` ‚Üí **ƒê√£ quy·∫øt ƒë·ªãnh**
- [x] Thi·∫øt k·∫ø API Edge Function: input/output format ‚Üí **ƒê√£ thi·∫øt k·∫ø**

**‚úÖ Ho√†n th√†nh:** 2024-12-XX

**File li√™n quan:**
- `services/chatService.js`
- `supabase/functions/merge-chunks/index.ts` (m·ªõi)

---

### ‚úÖ Task 2: T·∫°o helper function chia file th√†nh chunks
**M√¥ t·∫£:** T·∫°o function ƒë·ªÉ ƒë·ªçc file t·ª´ng ph·∫ßn, tr√°nh load to√†n b·ªô v√†o memory

**Chi ti·∫øt:**
- [x] T·∫°o `readFileChunk(fileUri, start, end)`: ƒë·ªçc file t·ª´ offset start ƒë·∫øn end ‚Üí **ƒê√£ t·∫°o `extractChunkFromBase64`**
- [x] S·ª≠ d·ª•ng `expo-file-system` v·ªõi `readAsStringAsync` v√† offset/limit ‚Üí **ƒê√£ implement**
- [x] X·ª≠ l√Ω base64 encoding cho t·ª´ng chunk ‚Üí **ƒê√£ x·ª≠ l√Ω decode/encode**
- [x] T√≠nh to√°n s·ªë l∆∞·ª£ng chunks d·ª±a tr√™n file size v√† chunk size ‚Üí **ƒê√£ implement**
- [x] T·∫°o function `splitFileIntoChunks(file, chunkSize)`: tr·∫£ v·ªÅ array chunks ‚Üí **ƒê√£ t·∫°o**

**‚úÖ Ho√†n th√†nh:** 2024-12-XX

**Logging ƒë√£ th√™m:**
- Log file size (MB v√† bytes)
- Log s·ªë l∆∞·ª£ng chunks ƒë√£ chia
- Log th√¥ng tin t·ª´ng chunk (index, start, end, size)
- Log t·ªïng k√≠ch th∆∞·ªõc chunks

**File li√™n quan:**
- `services/chatService.js` (th√™m helper functions)

**Code m·∫´u:**
```javascript
const readFileChunk = async (fileUri, start, end) => {
  // ƒê·ªçc file t·ª´ start ƒë·∫øn end
  // Tr·∫£ v·ªÅ base64 string c·ªßa chunk
};

const splitFileIntoChunks = async (file, chunkSize = 2 * 1024 * 1024) => {
  // T√≠nh s·ªë chunks
  // ƒê·ªçc t·ª´ng chunk
  // Tr·∫£ v·ªÅ array chunks v·ªõi metadata (index, start, end, data)
};
```

---

## üîß PHASE 2: Core Upload Logic

### ‚úÖ Task 3: T·∫°o h√†m upload single chunk
**M√¥ t·∫£:** Upload 1 chunk l√™n Supabase Storage v·ªõi t√™n file temp

**Chi ti·∫øt:**
- [ ] T·∫°o `uploadSingleChunk(chunkData, fileId, chunkIndex, type)`
- [ ] Upload l√™n path: `temp/chunks/{fileId}/chunk_{chunkIndex}`
- [ ] X·ª≠ l√Ω error v√† retry logic c∆° b·∫£n
- [ ] Tr·∫£ v·ªÅ path c·ªßa chunk ƒë√£ upload
- [ ] Log progress cho t·ª´ng chunk

**File li√™n quan:**
- `services/chatService.js`

**Code m·∫´u:**
```javascript
const uploadSingleChunk = async (chunkData, fileId, chunkIndex, type) => {
  const chunkPath = `temp/chunks/${fileId}/chunk_${chunkIndex}`;
  const { data, error } = await supabase.storage
    .from('media')
    .upload(chunkPath, chunkData, {
      contentType: type === 'image' ? 'image/*' : 'video/*'
    });
  return { success: !error, path: chunkPath, error };
};
```

---

### ‚úÖ Task 4: T·∫°o h√†m upload chunks parallel
**M√¥ t·∫£:** Upload nhi·ªÅu chunks song song v·ªõi progress tracking

**Chi ti·∫øt:**
- [ ] T·∫°o `uploadChunksParallel(chunks, fileId, type, onProgress)`
- [ ] Upload 3-5 chunks c√πng l√∫c (batch)
- [ ] Track progress: `(uploadedChunks / totalChunks) * 80` (80% cho upload)
- [ ] G·ªçi `onProgress` callback sau m·ªói batch
- [ ] X·ª≠ l√Ω Promise.all v·ªõi error handling
- [ ] Tr·∫£ v·ªÅ array paths c·ªßa t·∫•t c·∫£ chunks ƒë√£ upload

**File li√™n quan:**
- `services/chatService.js`

**Code m·∫´u:**
```javascript
const uploadChunksParallel = async (chunks, fileId, type, onProgress) => {
  const MAX_PARALLEL = 3;
  const chunkPaths = [];
  
  for (let i = 0; i < chunks.length; i += MAX_PARALLEL) {
    const batch = chunks.slice(i, i + MAX_PARALLEL);
    const results = await Promise.all(
      batch.map((chunk, idx) => 
        uploadSingleChunk(chunk.data, fileId, i + idx, type)
      )
    );
    chunkPaths.push(...results.map(r => r.path));
    onProgress((chunkPaths.length / chunks.length) * 80);
  }
  
  return chunkPaths;
};
```

---

### ‚úÖ Task 5: T·∫°o Supabase Edge Function merge-chunks
**M√¥ t·∫£:** Merge t·∫•t c·∫£ chunks th√†nh 1 file v√† upload l√™n v·ªã tr√≠ cu·ªëi c√πng

**Chi ti·∫øt:**
- [ ] T·∫°o `supabase/functions/merge-chunks/index.ts`
- [ ] Nh·∫≠n input: `{ fileId, chunkPaths, finalPath, contentType }`
- [ ] Download t·∫•t c·∫£ chunks t·ª´ Storage
- [ ] Merge chunks th√†nh 1 ArrayBuffer/Uint8Array
- [ ] Upload file ƒë√£ merge l√™n `finalPath`
- [ ] X√≥a t·∫•t c·∫£ temp chunks sau khi merge th√†nh c√¥ng
- [ ] Tr·∫£ v·ªÅ public URL c·ªßa file cu·ªëi c√πng
- [ ] Error handling v√† cleanup n·∫øu merge th·∫•t b·∫°i

**File li√™n quan:**
- `supabase/functions/merge-chunks/index.ts` (m·ªõi)
- `supabase/functions/merge-chunks/deno.json` (m·ªõi)

**Code m·∫´u:**
```typescript
serve(async (req) => {
  const { fileId, chunkPaths, finalPath, contentType } = await req.json();
  
  // 1. Download t·∫•t c·∫£ chunks
  const chunks = await Promise.all(
    chunkPaths.map(path => 
      supabase.storage.from('media').download(path)
    )
  );
  
  // 2. Merge chunks
  const totalSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
  const mergedBuffer = new Uint8Array(totalSize);
  let offset = 0;
  for (const chunk of chunks) {
    mergedBuffer.set(chunk, offset);
    offset += chunk.length;
  }
  
  // 3. Upload merged file
  await supabase.storage.from('media').upload(finalPath, mergedBuffer, { contentType });
  
  // 4. Cleanup temp chunks
  await supabase.storage.from('media').remove(chunkPaths);
  
  // 5. Get public URL
  const { data } = supabase.storage.from('media').getPublicUrl(finalPath);
  return new Response(JSON.stringify({ url: data.publicUrl }));
});
```

---

### ‚úÖ Task 6: T·∫°o h√†m uploadMediaFileChunked (wrapper)
**M√¥ t·∫£:** Function ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô flow chunk upload

**Chi ti·∫øt:**
- [ ] T·∫°o `uploadMediaFileChunked(file, type, onProgress)`
- [ ] T·∫°o unique fileId cho session upload
- [ ] G·ªçi `splitFileIntoChunks` ƒë·ªÉ chia file
- [ ] G·ªçi `uploadChunksParallel` ƒë·ªÉ upload (progress 0-80%)
- [ ] G·ªçi Edge Function `merge-chunks` (progress 80-100%)
- [ ] Tr·∫£ v·ªÅ k·∫øt qu·∫£ gi·ªëng `uploadMediaFile` (success, data, metrics)
- [ ] Error handling v√† cleanup n·∫øu th·∫•t b·∫°i

**File li√™n quan:**
- `services/chatService.js`

**Code m·∫´u:**
```javascript
export const uploadMediaFileChunked = async (file, type = 'image', onProgress) => {
  const fileId = `${Date.now()}_${Math.random().toString(36).substring(2)}`;
  const folderName = type === 'image' ? 'images' : 'videos';
  const fileExt = file.uri.split('.').pop();
  const finalPath = `${folderName}/${fileId}.${fileExt}`;
  
  try {
    // 1. Chia file th√†nh chunks
    onProgress?.(0);
    const chunks = await splitFileIntoChunks(file, CHUNK_SIZE);
    
    // 2. Upload chunks parallel
    const chunkPaths = await uploadChunksParallel(
      chunks, 
      fileId, 
      type, 
      (progress) => onProgress?.(progress * 0.8) // 0-80%
    );
    
    // 3. Merge chunks
    const mergeResult = await supabase.functions.invoke('merge-chunks', {
      body: { fileId, chunkPaths, finalPath, contentType: type === 'image' ? 'image/*' : 'video/*' }
    });
    onProgress?.(100);
    
    // 4. Tr·∫£ v·ªÅ k·∫øt qu·∫£
    return {
      success: true,
      data: {
        file_url: mergeResult.data.url,
        file_path: finalPath,
        file_name: `${fileId}.${fileExt}`,
        file_size: file.fileSize || 0,
        mime_type: file.mimeType || (type === 'image' ? 'image/jpeg' : 'video/mp4')
      }
    };
  } catch (error) {
    // Cleanup temp chunks n·∫øu l·ªói
    return { success: false, msg: error.message };
  }
};
```

---

## üõ°Ô∏è PHASE 3: Error Handling & Retry

### ‚úÖ Task 7: Th√™m retry logic cho t·ª´ng chunk
**M√¥ t·∫£:** Retry t·ª± ƒë·ªông khi upload chunk th·∫•t b·∫°i

**Chi ti·∫øt:**
- [ ] T·∫°o `uploadSingleChunkWithRetry(chunkData, fileId, chunkIndex, type, maxRetries = 3)`
- [ ] Retry v·ªõi exponential backoff: 1s, 2s, 4s
- [ ] Ch·ªâ retry chunk l·ªói, kh√¥ng retry to√†n b·ªô
- [ ] Log s·ªë l·∫ßn retry v√† k·∫øt qu·∫£
- [ ] Throw error n·∫øu retry h·∫øt l·∫ßn v·∫´n l·ªói

**File li√™n quan:**
- `services/chatService.js`

**Code m·∫´u:**
```javascript
const uploadSingleChunkWithRetry = async (chunkData, fileId, chunkIndex, type, maxRetries = 3) => {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await uploadSingleChunk(chunkData, fileId, chunkIndex, type);
    } catch (error) {
      if (attempt === maxRetries - 1) throw error;
      const delay = Math.pow(2, attempt) * 1000; // 1s, 2s, 4s
      await new Promise(resolve => setTimeout(resolve, delay));
      console.log(`[Retry] Retrying chunk ${chunkIndex}, attempt ${attempt + 1}/${maxRetries}`);
    }
  }
};
```

---

### ‚úÖ Task 11: X·ª≠ l√Ω error handling t·ªïng th·ªÉ
**M√¥ t·∫£:** Cleanup v√† error messages r√µ r√†ng

**Chi ti·∫øt:**
- [ ] Cleanup temp chunks n·∫øu upload th·∫•t b·∫°i (g·ªçi Edge Function cleanup ho·∫∑c x√≥a tr·ª±c ti·∫øp)
- [ ] Hi·ªÉn th·ªã error message r√µ r√†ng cho user
- [ ] Log chi ti·∫øt ƒë·ªÉ debug: file size, s·ªë chunks, chunks l·ªói
- [ ] X·ª≠ l√Ω timeout: n·∫øu upload qu√° l√¢u (> 5 ph√∫t) th√¨ cancel
- [ ] X·ª≠ l√Ω network error: detect v√† retry to√†n b·ªô n·∫øu c·∫ßn

**File li√™n quan:**
- `services/chatService.js`
- `app/(main)/chat.jsx`

---

## üìä PHASE 4: Progress & UI

### ‚úÖ Task 8: Th√™m progress tracking chi ti·∫øt
**M√¥ t·∫£:** Track progress cho t·ª´ng b∆∞·ªõc v√† callback ƒë·ªÉ update UI

**Chi ti·∫øt:**
- [ ] Progress cho ƒë·ªçc file: 0-10%
- [ ] Progress cho chia chunks: 10-15%
- [ ] Progress cho upload chunks: 15-80% (t·ª´ng chunk)
- [ ] Progress cho merge: 80-100%
- [ ] Callback `onProgress(percent)` ƒë·ªÉ update UI
- [ ] Log progress trong console ƒë·ªÉ debug

**File li√™n quan:**
- `services/chatService.js`
- `app/(main)/chat.jsx`

---

### ‚úÖ Task 9: C·∫≠p nh·∫≠t sendMediaMessage trong chat.jsx
**M√¥ t·∫£:** S·ª≠ d·ª•ng chunk upload v√† hi·ªÉn th·ªã progress bar

**Chi ti·∫øt:**
- [ ] Thay `uploadMediaFile` ‚Üí `uploadMediaFileChunked` (cho file >= 5MB)
- [ ] Th√™m state `uploadProgress` ƒë·ªÉ track progress
- [ ] Hi·ªÉn th·ªã progress bar trong UI khi upload
- [ ] Update progress bar theo `onProgress` callback
- [ ] ·∫®n progress bar khi upload xong
- [ ] Gi·ªØ nguy√™n logic g·ª≠i message sau khi upload

**File li√™n quan:**
- `app/(main)/chat.jsx`

**UI m·∫´u:**
```jsx
{uploading && (
  <View style={styles.progressContainer}>
    <ProgressBar progress={uploadProgress} />
    <Text>{uploadProgress}%</Text>
  </View>
)}
```

---

## ‚ö° PHASE 5: T·ªëi ∆∞u & Hybrid

### ‚úÖ Task 10: Th√™m logic quy·∫øt ƒë·ªãnh khi n√†o d√πng chunk upload
**M√¥ t·∫£:** Hybrid approach - file nh·ªè upload tr·ª±c ti·∫øp, file l·ªõn d√πng chunk

**Chi ti·∫øt:**
- [ ] X√°c ƒë·ªãnh threshold: 5MB
- [ ] File < 5MB: d√πng `uploadMediaFile` (nh∆∞ hi·ªán t·∫°i)
- [ ] File ‚â• 5MB: d√πng `uploadMediaFileChunked`
- [ ] T·ª± ƒë·ªông ch·ªçn method d·ª±a tr√™n `file.fileSize`
- [ ] Log method ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ debug

**File li√™n quan:**
- `services/chatService.js`
- `app/(main)/chat.jsx`

**Code m·∫´u:**
```javascript
const CHUNK_UPLOAD_THRESHOLD = 5 * 1024 * 1024; // 5MB

const uploadResult = file.fileSize >= CHUNK_UPLOAD_THRESHOLD
  ? await uploadMediaFileChunked(file, type, onProgress)
  : await uploadMediaFile(file, type);
```

---

## üß™ PHASE 6: Testing & Metrics

### ‚úÖ Task 12: Test v√† t·ªëi ∆∞u
**M√¥ t·∫£:** Test v·ªõi nhi·ªÅu tr∆∞·ªùng h·ª£p kh√°c nhau

**Chi ti·∫øt:**
- [ ] Test v·ªõi file nh·ªè (< 5MB): verify upload tr·ª±c ti·∫øp
- [ ] Test v·ªõi file trung b√¨nh (5-20MB): verify chunk upload
- [ ] Test v·ªõi file l·ªõn (> 20MB): verify performance
- [ ] Test v·ªõi m·∫°ng ch·∫≠m: verify retry logic
- [ ] Test v·ªõi m·∫°ng b·ªã ng·∫Øt: verify error handling
- [ ] Test retry logic: simulate chunk upload l·ªói
- [ ] So s√°nh th·ªùi gian upload: chunk vs non-chunk
- [ ] Test memory usage: verify kh√¥ng load to√†n b·ªô file

**Test cases:**
1. Upload ·∫£nh 2MB ‚Üí D√πng upload tr·ª±c ti·∫øp
2. Upload ·∫£nh 8MB ‚Üí D√πng chunk upload (4 chunks x 2MB)
3. Upload video 30MB ‚Üí D√πng chunk upload (15 chunks x 2MB)
4. Simulate chunk 3 l·ªói ‚Üí Verify retry 3 l·∫ßn
5. Simulate network timeout ‚Üí Verify cleanup

---

### ‚úÖ Task 13: Th√™m metrics v√† logging
**M√¥ t·∫£:** Log chi ti·∫øt ƒë·ªÉ theo d√µi v√† so s√°nh performance

**Chi ti·∫øt:**
- [ ] Log th·ªùi gian upload t·ª´ng chunk
- [ ] Log t·ªïng th·ªùi gian upload
- [ ] Log t·ªëc ƒë·ªô upload (MB/s)
- [ ] Log s·ªë l·∫ßn retry
- [ ] Log memory usage (∆∞·ªõc t√≠nh)
- [ ] So s√°nh v·ªõi upload c≈©: th·ªùi gian, memory, t·ªëc ƒë·ªô
- [ ] Log s·ªë l∆∞·ª£ng chunks v√† chunk size

**File li√™n quan:**
- `services/chatService.js`

**Metrics m·∫´u:**
```javascript
const metrics = {
  fileSize: file.fileSize,
  chunkSize: CHUNK_SIZE,
  totalChunks: chunks.length,
  uploadTime: uploadEndTime - uploadStartTime,
  uploadSpeed: file.fileSize / (uploadTime / 1000), // MB/s
  retryCount: totalRetries,
  memoryPeak: chunkSize * MAX_PARALLEL, // ∆Ø·ªõc t√≠nh
  method: 'chunked' // ho·∫∑c 'direct'
};
```

---

## üéØ Flow t·ªïng th·ªÉ

```
1. User ch·ªçn ·∫£nh/video
   ‚Üì
2. Ki·ªÉm tra file size
   - < 5MB ‚Üí Upload tr·ª±c ti·∫øp (uploadMediaFile)
   - ‚â• 5MB ‚Üí Chunk upload (uploadMediaFileChunked)
   ‚Üì
3. [Chunk Upload] Chia file th√†nh chunks (2MB/chunk)
   ‚Üì
4. [Chunk Upload] Upload chunks song song (3-5 chunks/l·∫ßn)
   - Progress: 0-80%
   - Retry n·∫øu l·ªói
   ‚Üì
5. [Chunk Upload] G·ªçi Edge Function merge-chunks
   - Progress: 80-100%
   ‚Üì
6. Nh·∫≠n URL file cu·ªëi c√πng
   ‚Üì
7. G·ª≠i message v·ªõi file_url
```

---

## üìù Th·ª© t·ª± ∆∞u ti√™n

### üî¥ **Cao (Core functionality)**
1. Task 1: Thi·∫øt k·∫ø ki·∫øn tr√∫c
2. Task 2: Helper function chia file
3. Task 3: Upload single chunk
4. Task 4: Upload parallel
5. Task 5: Edge Function merge
6. Task 6: Wrapper function

### üü° **Trung b√¨nh (Error handling & UI)**
7. Task 7: Retry logic
8. Task 8: Progress tracking
9. Task 9: Update UI
10. Task 11: Error handling

### üü¢ **Th·∫•p (T·ªëi ∆∞u & Testing)**
11. Task 10: Hybrid approach
12. Task 12: Testing
13. Task 13: Metrics

---

## üìå Notes

- **Chunk size**: B·∫Øt ƒë·∫ßu v·ªõi 2MB, c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh sau
- **Parallel uploads**: B·∫Øt ƒë·∫ßu v·ªõi 3 chunks c√πng l√∫c, test v√† t·ªëi ∆∞u
- **Edge Function**: C·∫ßn deploy l√™n Supabase tr∆∞·ªõc khi test
- **Backward compatibility**: Gi·ªØ `uploadMediaFile` cho file nh·ªè
- **Memory**: Chunk upload gi·∫£m memory t·ª´ ~90MB xu·ªëng ~6MB (v·ªõi 2MB chunks)

---

## ‚úÖ Checklist ho√†n th√†nh

- [ ] Phase 1: Thi·∫øt k·∫ø & Setup
- [ ] Phase 2: Core Upload Logic
- [ ] Phase 3: Error Handling & Retry
- [ ] Phase 4: Progress & UI
- [ ] Phase 5: T·ªëi ∆∞u & Hybrid
- [ ] Phase 6: Testing & Metrics

---

**Ng√†y t·∫°o:** 2024-12-XX  
**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi:** 2024-12-XX

